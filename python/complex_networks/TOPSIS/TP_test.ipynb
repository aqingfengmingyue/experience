{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f1185-f24d-4adc-bc9e-99820e398048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "class Topsis:\n",
    "\n",
    "    '''\n",
    "\tCreate an evaluation matrix consisting of m alternatives and n criteria,\n",
    "\twith the intersection of each alternative and criteria given as {\\displaystyle x_{ij}}x_{ij},\n",
    "\twe therefore have a matrix {\\displaystyle (x_{ij})_{m\\times n}}(x_{{ij}})_{{m\\times n}}.\n",
    "\t'''\n",
    "\n",
    "    def __init__(self, evaluation_matrix, weight_matrix, criteria, normalization=True):\n",
    "        self.normalization = normalization\n",
    "        \n",
    "        # M×N matrix\n",
    "        self.evaluation_matrix = np.array(evaluation_matrix, dtype=\"float\")\n",
    "        self.normalized_decision = np.array([])  # 初始化归一矩阵\n",
    "        self.weighted_normalized = np.array([])  # Weight matrix\n",
    "        \n",
    "        # M alternatives (options)\n",
    "        self.row_size = len(self.evaluation_matrix)\n",
    "\n",
    "        # N attributes/criteria\n",
    "        self.column_size = len(self.evaluation_matrix[0])\n",
    "\n",
    "        # N size weight matrix\n",
    "        if weight_matrix[0]:\n",
    "            self.weight_matrix = np.array(weight_matrix, dtype=\"float\")\n",
    "        self.criteria = np.array(criteria, dtype=\"float\")\n",
    "\n",
    "    '''\n",
    "\t# Step 2\n",
    "\tThe matrix {\\displaystyle (x_{ij})_{m\\times n}}(x_{{ij}})_{{m\\times n}} is then normalised to form the matrix\n",
    "\t'''\n",
    "\n",
    "    def step_2(self):\n",
    "        # normalized scores\n",
    "        self.normalized_decision = self.evaluation_matrix\n",
    "        if self.normalization:\n",
    "            sqrd_sum = np.zeros(self.column_size)\n",
    "            for i in range(self.row_size):\n",
    "                for j in range(self.column_size):\n",
    "                    sqrd_sum[j] += self.evaluation_matrix[i, j]**2\n",
    "            for i in range(self.row_size):\n",
    "                for j in range(self.column_size):\n",
    "                    self.normalized_decision[i,\n",
    "                                             j] = self.evaluation_matrix[i, j]/(sqrd_sum[j]**0.5)\n",
    "                    \n",
    "\n",
    "    '''\n",
    "\t# Step 3\n",
    "\tCalculate the weighted normalised decision matrix\n",
    "\t'''\n",
    "\n",
    "    def step_3(self):\n",
    "        from pdb import set_trace\n",
    "        self.weighted_normalized = self.normalized_decision\n",
    "        if self.weight_matrix[0]:\n",
    "            for i in range(self.row_size):\n",
    "                for j in range(self.column_size):\n",
    "                    self.weighted_normalized[i, j] *= self.weight_matrix[j]\n",
    "            \n",
    "            \n",
    "\n",
    "    '''\n",
    "\t# Step 4\n",
    "\tDetermine the worst alternative {\\displaystyle (A_{w})}(A_{w}) and the best alternative {\\displaystyle (A_{b})}(A_{b}):\n",
    "\t'''\n",
    "\n",
    "    def step_4(self):\n",
    "        self.worst_alternatives = np.zeros(self.column_size)\n",
    "        self.best_alternatives = np.zeros(self.column_size)\n",
    "        for i in range(self.column_size):\n",
    "            if self.criteria[i]:\n",
    "                self.worst_alternatives[i] = min(\n",
    "                    self.weighted_normalized[:, i])\n",
    "                self.best_alternatives[i] = max(self.weighted_normalized[:, i])\n",
    "            else:\n",
    "                self.worst_alternatives[i] = max(\n",
    "                    self.weighted_normalized[:, i])\n",
    "                self.best_alternatives[i] = min(self.weighted_normalized[:, i])\n",
    "\n",
    "    '''\n",
    "\t# Step 5\n",
    "\tCalculate the L2-distance between the target alternative {\\displaystyle i}i and the worst condition {\\displaystyle A_{w}}A_{w}\n",
    "\t{\\displaystyle d_{iw}={\\sqrt {\\sum _{j=1}^{n}(t_{ij}-t_{wj})^{2}}},\\quad i=1,2,\\ldots ,m,}\n",
    "\tand the distance between the alternative {\\displaystyle i}i and the best condition {\\displaystyle A_{b}}A_b\n",
    "\t{\\displaystyle d_{ib}={\\sqrt {\\sum _{j=1}^{n}(t_{ij}-t_{bj})^{2}}},\\quad i=1,2,\\ldots ,m}\n",
    "\twhere {\\displaystyle d_{iw}}d_{{iw}} and {\\displaystyle d_{ib}}d_{{ib}} are L2-norm distances \n",
    "\tfrom the target alternative {\\displaystyle i}i to the worst and best conditions, respectively.\n",
    "\t'''\n",
    "\n",
    "    def step_5(self):\n",
    "        self.worst_distance = np.zeros(self.row_size)\n",
    "        self.best_distance = np.zeros(self.row_size)\n",
    "\n",
    "        self.worst_distance_mat = np.copy(self.weighted_normalized) \n",
    "        self.best_distance_mat = np.copy(self.weighted_normalized)\n",
    "        '''\n",
    "        copy是复制一个独立的副本给另一个变量，如果去除copy相当于两个不同变量名称的变量储存在同一个内存位置。\n",
    "        所以，改变任意一个变量另一个变量也会跟着改变，因为他们俩的物理内存是同一个\n",
    "        '''\n",
    "\n",
    "        for i in range(self.row_size):\n",
    "            for j in range(self.column_size):\n",
    "                # 通过self定义的属性在整个实例生命周期都可以使用不必要必须定义在__init__中\n",
    "                self.worst_distance_mat[i][j] = (self.weighted_normalized[i][j]-self.worst_alternatives[j])**2\n",
    "                self.best_distance_mat[i][j] = (self.weighted_normalized[i][j]-self.best_alternatives[j])**2\n",
    "                \n",
    "                self.worst_distance[i] += self.worst_distance_mat[i][j]\n",
    "                self.best_distance[i] += self.best_distance_mat[i][j] \n",
    "\n",
    "        for i in range(self.row_size):\n",
    "            self.worst_distance[i] = self.worst_distance[i]**0.5\n",
    "            self.best_distance[i] = self.best_distance[i]**0.5\n",
    "\n",
    "    '''\n",
    "\t# Step 6\n",
    "\tCalculate the similarity\n",
    "\t'''\n",
    "\n",
    "    def step_6(self):\n",
    "        np.seterr(all='ignore')\n",
    "        self.worst_similarity = np.zeros(self.row_size)\n",
    "        self.best_similarity = np.zeros(self.row_size)\n",
    "\n",
    "        for i in range(self.row_size):\n",
    "            # calculate the similarity to the worst condition\n",
    "            self.worst_similarity[i] = self.best_distance[i] / \\\n",
    "                (self.worst_distance[i]+self.best_distance[i])\n",
    "\n",
    "            # calculate the similarity to the best condition\n",
    "            self.best_similarity[i] = self.worst_distance[i] / \\\n",
    "                (self.worst_distance[i]+self.best_distance[i])\n",
    "            \n",
    "\n",
    "    def calc(self):\n",
    "        self.step_2()\n",
    "        self.step_3()\n",
    "        self.step_4()\n",
    "        self.step_5()\n",
    "        self.step_6()\n",
    "        best_similarity_result = {index: value for index, value in enumerate(self.best_similarity)}\n",
    "        ranked_dic = dict(sorted(best_similarity_result.items(),\n",
    "                                 key=lambda item: item[1], reverse=True))#按照中心性值大小降序排名\n",
    "        \n",
    "        # print(\"Step 1\\n\", self.evaluation_matrix, end=\"\\n\\n\")\n",
    "        # print(\"Step 2\\n\", self.normalized_decision, end=\"\\n\\n\")\n",
    "        # print(\"Step 3\\n\", self.weighted_normalized, end=\"\\n\\n\")\n",
    "        # print(\"Step 4\\n\", self.worst_alternatives,\n",
    "        #       self.best_alternatives, end=\"\\n\\n\")\n",
    "        # print(\"Step 5\\n\", self.worst_distance, self.best_distance, end=\"\\n\\n\")\n",
    "        # print(\"Step 6\\n\", self.worst_similarity,\n",
    "        #       self.best_similarity, end=\"\\n\\n\")\n",
    "    \n",
    "        return ranked_dic  # 返回降序排名的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85da7b21-7c83-4db1-949f-0612a5875002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# 创建一个随机图\n",
    "n_nodes = 200  # 指定节点数\n",
    "p = 0.3  # 每条边存在的概率\n",
    "G = nx.gnp_random_graph(n_nodes, p)#全称是 G(n, p)，表示给定 n 个节点，每对节点之间有一个概率 p 来决定是否存在一条边\n",
    "# nx.draw(G, with_labels=True, font_weight='bold')#无向\n",
    "DC = nx.degree_centrality(G)\n",
    "# print(DC)\n",
    "CC = nx.closeness_centrality(G)\n",
    "# print(CC)\n",
    "BC = nx.betweenness_centrality(G)\n",
    "# print(BC)\n",
    "DC_array = np.array(list(DC.values()))\n",
    "CC_array = np.array(list(CC.values()))\n",
    "BC_array = np.array(list(BC.values()))\n",
    "decision_matrix = np.column_stack((DC_array, CC_array, BC_array))\n",
    "# print(decision_matrix)\n",
    "\n",
    "# 根据TOPSIS方法计算对节点进行排序\n",
    "weights = [1, 1, 1]\n",
    "criterias = np.array([True, True, True])\n",
    "t = Topsis(decision_matrix, weights, criterias, normalization=False)\n",
    "consequence = t.calc()\n",
    "\n",
    "#按照中心性值大小降序排名，将各中心性排名结果进行输出\n",
    "sorted_DC = dict(sorted(DC.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_CC = dict(sorted(CC.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_BC = dict(sorted(BC.items(), key=lambda item: item[1], reverse=True))\n",
    "DC_array_keys = np.array(list(sorted_DC.keys()))\n",
    "CC_array_keys = np.array(list(sorted_CC.keys()))\n",
    "BC_array_keys = np.array(list(sorted_BC.keys()))\n",
    "TOPSISI_array_keys = np.array(list(consequence.keys()))\n",
    "compare_matrix = np.column_stack((DC_array_keys, CC_array_keys, BC_array_keys, TOPSISI_array_keys))\n",
    "print(compare_matrix[: 20, :])\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"代码运行时间: {elapsed_time} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ddf9f9-55d0-48bb-becb-a12cfadecd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# 创建一个随机图\n",
    "n_nodes = 2000  # 指定节点数\n",
    "p = 0.3  # 每条边存在的概率\n",
    "G = nx.gnp_random_graph(n_nodes, p)#全称是 G(n, p)，表示给定 n 个节点，每对节点之间有一个概率 p 来决定是否存在一条边\n",
    "# nx.draw(G, with_labels=True, font_weight='bold')#无向\n",
    "DC = nx.degree_centrality(G)\n",
    "# print(DC)\n",
    "CC = nx.closeness_centrality(G)\n",
    "# print(CC)\n",
    "BC = nx.betweenness_centrality(G)\n",
    "# print(BC)\n",
    "DC_array = np.array(list(DC.values()))\n",
    "CC_array = np.array(list(CC.values()))\n",
    "BC_array = np.array(list(BC.values()))\n",
    "decision_matrix = np.column_stack((DC_array, CC_array, BC_array))\n",
    "# print(decision_matrix)\n",
    "\n",
    "# 根据TOPSIS方法计算对节点进行排序\n",
    "weights = [1, 1, 1]\n",
    "criterias = np.array([True, True, True])\n",
    "t = Topsis(decision_matrix, weights, criterias, normalization=False)\n",
    "consequence = t.calc()\n",
    "\n",
    "#按照中心性值大小降序排名，将各中心性排名结果进行输出\n",
    "sorted_DC = dict(sorted(DC.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_CC = dict(sorted(CC.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_BC = dict(sorted(BC.items(), key=lambda item: item[1], reverse=True))\n",
    "DC_array_keys = np.array(list(sorted_DC.keys()))\n",
    "CC_array_keys = np.array(list(sorted_CC.keys()))\n",
    "BC_array_keys = np.array(list(sorted_BC.keys()))\n",
    "TOPSISI_array_keys = np.array(list(consequence.keys()))\n",
    "compare_matrix = np.column_stack((DC_array_keys, CC_array_keys, BC_array_keys, TOPSISI_array_keys))\n",
    "print(compare_matrix[: 20, :])\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"代码运行时间: {elapsed_time} 秒\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
